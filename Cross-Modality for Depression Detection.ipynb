{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LayerNormalization\n",
    "from tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D, Layer, Add, Concatenate\n",
    "from transformers import TFXLMRobertaModel\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the train labels\n",
    "- Load the test lables\n",
    "- Load the text and audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text model &rarr; Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model = TFXLMRobertaModel.from_pretrained(\"xlm-roberta-base\") #another option: xlm-roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(embeddings, num_heads, dff, dropout_rate=0.3):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embeddings.shape[-1])(embeddings, embeddings)\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(embeddings+attn_output)\n",
    "    \n",
    "    ffn_output = Dense(dff, activation=tf.nn.gelu)(out1)\n",
    "    ffn_output = Dense(embeddings.shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(out1+ffn_output)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 252\n",
    "\n",
    "def create_roberta_text_model():\n",
    "    text_input_ids = Input(shape=(MAX_LENGTH,), dtype=tf.int32)\n",
    "    roberta_output = roberta_model(text_input_ids)\n",
    "    roberta_embeddings = roberta_output[0]\n",
    "    \n",
    "    transformer_output = transformer_block(roberta_embeddings, num_heads=6, dff=512)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(transformer_output)\n",
    "    \n",
    "    return tf.keras.Model(inputs=text_input_ids, outputs=x)\n",
    "\n",
    "text_model = create_roberta_text_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio model &rarr; MLP-Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_input_shape = (train_audio_features.shape[1], train_audio_features.shape[2])\n",
    "\n",
    "class MixerLayer(Layer):\n",
    "    def __init__(self, tokens_mlp_dim, channels_mlp_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.tokens_mlp_dim = tokens_mlp_dim\n",
    "        self.channels_mlp_dim = channels_mlp_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dense1 = Dense(self.tokens_mlp_dim, activation=tf.nn.gelu)\n",
    "        self.dense2 = Dense(input_shape[1], activation=tf.nn.gelu)\n",
    "        self.dense3 = Dense(self.channels_mlp_dim, activation=tf.nn.gelu)\n",
    "        self.dense4 = Dense(input_shape[2], activation=tf.nn.gelu)\n",
    "        self.dropout = Dropout(self.dropout_rate)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Token mixing\n",
    "        x = self.layer_norm1(inputs)\n",
    "        x_t = tf.transpose(x, perm=[0, 2, 1])\n",
    "        x_t = self.dense1(x_t)\n",
    "        x_t = self.dense2(x_t)\n",
    "        x_t = tf.transpose(x_t, perm=[0, 2, 1])\n",
    "        x = Add()([x, x_t])\n",
    "\n",
    "        # Channel mixing\n",
    "        y = self.layer_norm2(x)\n",
    "        y = self.dense3(y)\n",
    "        y = self.dense4(y)\n",
    "        y = Add()([x, y])\n",
    "        y = self.dropout(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mixer_model = Sequential([\n",
    "    Input(shape=audio_input_shape),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    MixerLayer(tokens_mlp_dim=32, channels_mlp_dim=32, dropout_rate=0.5),\n",
    "    GlobalAveragePooling1D()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion module - Cross modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.units = units\n",
    "        self.dense_query = Dense(units)\n",
    "        self.dense_key = Dense(units)\n",
    "        self.dense_value = Dense(units)\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        query, key = inputs\n",
    "        query = self.dense_query(query)\n",
    "        key = self.dense_key(key)\n",
    "        value = self.dense_value(key)\n",
    "        \n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        alignment = self.softmax(score)\n",
    "        context = tf.matmul(alignment, value)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModelWithText(tf.keras.Model):\n",
    "    def __init__(self, text_model, mlp_mixer_model):\n",
    "        super(CombinedModelWithText, self).__init__()\n",
    "        self.text_model = text_model\n",
    "        self.mlp_mixer_model = mlp_mixer_model\n",
    "        self.cross_attention_text = CrossAttention(64)\n",
    "        self.cross_attention_audio = CrossAttention(64)\n",
    "        self.fclayer = Dense(128, activation=tf.nn.gelu)\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.classifier = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        text_input, audio_input = inputs\n",
    "        text_output = self.text_model(text_input)\n",
    "        mlp_mixer_output = self.mlp_mixer_model(audio_input)\n",
    "        \n",
    "        cross_attention_text_output = self.cross_attention_text([text_output, mlp_mixer_output])\n",
    "        cross_attention_audio_output = self.cross_attention_audio([mlp_mixer_output, text_output])\n",
    "        \n",
    "        concatenated_output = Concatenate()([cross_attention_text_output, cross_attention_audio_output])\n",
    "        x = self.fclayer(concatenated_output)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create the combined model\n",
    "fusion_model = CombinedModelWithText(text_model, mlp_mixer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-6  # Change this value to adjust the learning rate\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "fusion_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)\n",
    "\n",
    "class_weights_list = class_weight.compute_sample_weight(class_weight='balanced', y=train_labels)\n",
    "class_weights = {0: class_weights_list[0], 1: class_weights_list[1]}\n",
    "\n",
    "fusion_model.fit((train_text_features, train_audio_features),train_labels, epochs=300, \n",
    "                  validation_split=0.2, batch_size=2, \n",
    "                  callbacks=[early_stopping], class_weight=class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dep-new",
   "language": "python",
   "name": "ai_dep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
